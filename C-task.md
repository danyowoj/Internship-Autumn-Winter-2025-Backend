Пользователи последних больших языковых моделей начали сталкиваться с проблемой - модель, сохраняя контекст в виде слов, может потреблять слишком много ресурсов. Конечно, эту проблему можно решить, найдя лучшее оборудование, но исследователи задались вопросом: а как сжать контекст, не потеряв точности? Ответ, к которому они пришли - объединять в один контекст вопросы пользователя, пересекающиеся хотя бы по одному слову. В качестве наглядных метрик они выбрали количество таких различных контекстов после всех запросов и размер (в уникальных словах) наибольшего из них. Например, если запросы пользователя - это "first prompt" и "second prompt", то они объединяются в один контекст размера 3, состоящий из слов "first", "second" и "prompt". Помогите исследователям придумать эффективный алгоритм сжатия контекста.
Формат ввода

В первой строке вводится число NN ( 1≤N≤10001≤N≤1000) - количество запросов от пользователя. Каждый запрос состоит из двух строк: на первой дано число MiMi​ ( 1≤Mi≤10001≤Mi​≤1000) - количество слов в ii-м запросе, а вторая строка - это сам запрос: MiMi​ слов из строчных английских букв длины от 11 до 1010, разделенных пробелом.
Формат вывода

В одной строке выведите два числа через пробел - кол-во контекстов и размер (в словах) самого большого из них.
Пример 1
Ввод
Вывод

3
4
a four word prompt
2
small prompt
5
unique line with five words

	

2 5

Пример 2
Ввод
Вывод

1
1
a

	

1 1

Пример 3
Ввод
Вывод

2
2
a b
2
b c

	

1 3

