# Подробное объяснение работы программы для сжатия контекста

## Общая идея алгоритма

Программа решает задачу объединения запросов в контексты, если они имеют хотя бы одно общее слово. Основная идея - представить запросы как узлы графа и соединить их ребрами, если они имеют общие слова. Затем найти связные компоненты этого графа - это и будут наши контексты.

## Детальное объяснение по шагам

### 1. Структура DSU (Disjoint Set Union)

```cpp
class DSU {
private:
    vector<int> parent;
    vector<int> rank;
public:
    DSU(int n) {
        parent.resize(n);
        rank.resize(n, 0);
        for (int i = 0; i < n; i++) {
            parent[i] = i;
        }
    }
    
    int find(int x) {
        if (parent[x] != x) {
            parent[x] = find(parent[x]);
        }
        return parent[x];
    }
    
    void unite(int x, int y) {
        x = find(x);
        y = find(y);
        if (x == y) return;
        if (rank[x] < rank[y]) {
            parent[x] = y;
        } else if (rank[x] > rank[y]) {
            parent[y] = x;
        } else {
            parent[y] = x;
            rank[x]++;
        }
    }
};
```

**DSU** - это структура данных для работы с непересекающимися множествами. Она позволяет:
- **find(x)** - находить представителя множества, к которому принадлежит x
- **unite(x, y)** - объединять два множества, содержащих x и y

**Оптимизации:**
- **Сжатие путей** в find(): при поиске представителя все узлы на пути перенаправляются к корню
- **Объединение по рангу** в unite(): множество с меньшим рангом присоединяется к множеству с большим рангом

### 2. Чтение и обработка входных данных

```cpp
vector<set<string>> queries(n);
for (int i = 0; i < n; i++) {
    int mi;
    cin >> mi;
    for (int j = 0; j < mi; j++) {
        string word;
        cin >> word;
        queries[i].insert(word);
    }
}
```

Каждый запрос хранится как `set<string>`, что автоматически обеспечивает:
- Уникальность слов в пределах одного запроса
- Быстрый поиск слов

### 3. Построение отображения слов на запросы

```cpp
unordered_map<string, vector<int>> word_map;
for (int i = 0; i < n; i++) {
    for (const string& word : queries[i]) {
        word_map[word].push_back(i);
    }
}
```

Создается словарь, где для каждого слова хранятся индексы всех запросов, содержащих это слово.

**Пример для "prompt" из первого примера:**
```
"prompt" -> [0, 1]  // встречается в запросах 0 и 1
```

### 4. Объединение запросов с общими словами

```cpp
for (auto& entry : word_map) {
    vector<int>& indices = entry.second;
    if (indices.size() > 1) {
        int first = indices[0];
        for (size_t k = 1; k < indices.size(); k++) {
            dsu.unite(first, indices[k]);
        }
    }
}
```

Для каждого слова, которое встречается в нескольких запросах, объединяем эти запросы в одну группу.

**Логика:**
- Если слово встречается в запросах A, B, C, то объединяем A с B, A с C
- В результате A, B, C окажутся в одном множестве

### 5. Формирование контекстов

```cpp
unordered_map<int, set<string>> component_words;
for (int i = 0; i < n; i++) {
    int root = dsu.find(i);
    component_words[root].insert(queries[i].begin(), queries[i].end());
}
```

Для каждого запроса находим корень его компоненты связности и добавляем все слова запроса в множество этой компоненты.

**Результат:** Каждая компонента содержит все уникальные слова из всех запросов, входящих в эту компоненту.

### 6. Подсчет результатов

```cpp
int max_size = 0;
for (auto& comp : component_words) {
    if (comp.second.size() > max_size) {
        max_size = comp.second.size();
    }
}
```

Находим максимальный размер контекста (количество уникальных слов в самой большой компоненте).

## Визуализация работы на примере

**Пример 1:**
```
Запрос 0: "a four word prompt"
Запрос 1: "small prompt"  
Запрос 2: "unique line with five words"
```

1. **Построение word_map:**
   - "prompt": [0, 1] - объединяет запросы 0 и 1
   - Остальные слова уникальны для своих запросов

2. **Компоненты связности:**
   - Компонента 0: запросы 0 и 1
   - Компонента 2: запрос 2

3. **Формирование контекстов:**
   - Контекст 0: {"a", "four", "word", "prompt", "small"} - 5 слов
   - Контекст 2: {"unique", "line", "with", "five", "words"} - 5 слов

4. **Результат:** 2 контекста, максимальный размер = 5

## Сложность алгоритма

- **Время:** O(N × M + W × K²), где:
  - N - количество запросов
  - M - среднее количество слов в запросе
  - W - количество уникальных слов
  - K - максимальное количество запросов, содержащих одно слово

- **Память:** O(N × M) для хранения запросов и O(W) для word_map

Алгоритм эффективно решает задачу благодаря использованию DSU для объединения множеств и хеш-таблиц для быстрого доступа к данным.
